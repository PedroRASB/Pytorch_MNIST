{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6037, 0.5431, 0.1864],\n",
      "        [0.5290, 0.2139, 0.2981],\n",
      "        [0.9678, 0.5666, 0.0867],\n",
      "        [0.2362, 0.8536, 0.8173],\n",
      "        [0.2624, 0.0129, 0.1692]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "mnist_train=tv.datasets.MNIST(root='./Data',train=True,download=True)\n",
    "mnist_test=tv.datasets.MNIST(root='./Data',train=False,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ./Data\n",
       "    Transforms (if any): None\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x7FE3AF47FF60>,\n",
       " tensor(0, device='cpu'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranforming in tensors and grayscale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(num_output_channels=1),transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "mnist_train=tv.datasets.MNIST(root='./Data',train=True,download=True,transform=transform)\n",
    "mnist_test=tv.datasets.MNIST(root='./Data',train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ./Data\n",
       "    Transforms (if any): Compose(\n",
       "                             Grayscale(num_output_channels=1)\n",
       "                             ToTensor()\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Split: test\n",
       "    Root Location: ./Data\n",
       "    Transforms (if any): Compose(\n",
       "                             Grayscale(num_output_channels=1)\n",
       "                             ToTensor()\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]], device='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FE396EAFE10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pil = tv.transforms.ToPILImage()\n",
    "img = to_pil(mnist_train[0][0])\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train[0][1].cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28x28 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=data.DataLoader(mnist_train,batch_size=128,shuffle=True,num_workers=8)\n",
    "tester=data.DataLoader(mnist_test,batch_size=128,shuffle=True,num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__() #invoca o init de nn.Module\n",
    "        self.conv1 = nn.Conv2d(1,32,3, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32,64,3, padding=0)\n",
    "        self.conv3 = nn.Conv2d(64,64,3, padding=0)\n",
    "        self.conv4 = nn.Conv2d(64,64,3, padding=0)\n",
    "        self.drop1 = nn.Dropout(p=0.25)\n",
    "        self.lin1=nn.Linear(1024,128)\n",
    "        self.drop2 = nn.Dropout(p=0.5)\n",
    "        self.lin2=nn.Linear(128,64)\n",
    "        self.drop3 = nn.Dropout(p=0.5)\n",
    "        self.lin3=nn.Linear(64,10)\n",
    "        #self.soft=nn.Softmax(dim=1)\n",
    "    def forward(self,x):\n",
    "        x=f.relu(self.conv1(x))\n",
    "        x=f.relu(self.conv2(x))\n",
    "        x=f.max_pool2d(f.relu(self.conv3(x)),(2,2), padding=0)\n",
    "        x=f.max_pool2d(f.relu(self.conv4(x)),(2,2), padding=0)\n",
    "        x=self.drop1(x)\n",
    "        #y=x.size()\n",
    "        x=x.view(-1,1024)\n",
    "        x=f.relu(self.lin1(x))\n",
    "        x=self.drop2(x)\n",
    "        x=f.relu(self.lin2(x))\n",
    "        x=self.drop3(x)\n",
    "        x=self.lin3(x)\n",
    "       # y=x.size()\n",
    "       # x=self.soft(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x): #necessary?\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (drop1): Dropout(p=0.25)\n",
      "  (lin1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (drop2): Dropout(p=0.5)\n",
      "  (lin2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (drop3): Dropout(p=0.5)\n",
      "  (lin3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=Network()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "torch.Size([32, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "params=list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input=mnist_train[0][0].unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=net(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0727, -0.0545, -0.0881, -0.0860,  0.0193, -0.0471, -0.0037,  0.0856,\n",
       "          0.0033, -0.0571]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.0)#.9)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (drop1): Dropout(p=0.25)\n",
       "  (lin1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (drop2): Dropout(p=0.5)\n",
       "  (lin2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (drop3): Dropout(p=0.5)\n",
       "  (lin3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 ,loss: 2.303502363945121\n",
      "epoch: 1 ,loss: 2.3014023212481662\n",
      "epoch: 2 ,loss: 2.299924540875563\n",
      "epoch: 3 ,loss: 2.298519796399928\n",
      "epoch: 4 ,loss: 2.2947225575762262\n",
      "epoch: 5 ,loss: 2.2762315705386813\n",
      "epoch: 6 ,loss: 1.7113339578164921\n",
      "epoch: 7 ,loss: 0.7942710176968117\n",
      "epoch: 8 ,loss: 0.5019483613942478\n",
      "epoch: 9 ,loss: 0.39291277229150473\n",
      "epoch: 10 ,loss: 0.3261896855414295\n",
      "epoch: 11 ,loss: 0.28034946063497684\n",
      "epoch: 12 ,loss: 0.2523413136728537\n",
      "epoch: 13 ,loss: 0.23057553749571222\n",
      "epoch: 14 ,loss: 0.2162103899585794\n",
      "epoch: 15 ,loss: 0.19531095911190707\n",
      "epoch: 16 ,loss: 0.18385944628257994\n",
      "epoch: 17 ,loss: 0.17294467439148217\n",
      "epoch: 18 ,loss: 0.16482574786585785\n",
      "epoch: 19 ,loss: 0.15337889048971856\n",
      "epoch: 20 ,loss: 0.14752267029430313\n",
      "epoch: 21 ,loss: 0.1435559828644559\n",
      "epoch: 22 ,loss: 0.13785926135046395\n",
      "epoch: 23 ,loss: 0.13185965695948615\n",
      "epoch: 24 ,loss: 0.12758359852344242\n",
      "epoch: 25 ,loss: 0.12295589669903459\n",
      "epoch: 26 ,loss: 0.12007057356602474\n",
      "epoch: 27 ,loss: 0.1140067910652425\n",
      "epoch: 28 ,loss: 0.11116698128915926\n",
      "epoch: 29 ,loss: 0.10806241446831968\n",
      "epoch: 30 ,loss: 0.10745644853758152\n",
      "epoch: 31 ,loss: 0.10368147502734718\n",
      "epoch: 32 ,loss: 0.10053271633475575\n",
      "epoch: 33 ,loss: 0.09887406491299174\n",
      "epoch: 34 ,loss: 0.09435063388857887\n",
      "epoch: 35 ,loss: 0.09521257150957961\n",
      "epoch: 36 ,loss: 0.093058493707194\n",
      "epoch: 37 ,loss: 0.08896360733409299\n",
      "epoch: 38 ,loss: 0.08596807849337297\n",
      "epoch: 39 ,loss: 0.08808573910883113\n",
      "epoch: 40 ,loss: 0.08421567974012417\n",
      "epoch: 41 ,loss: 0.08517601951432507\n",
      "epoch: 42 ,loss: 0.0820863131544928\n",
      "epoch: 43 ,loss: 0.0794548255993105\n",
      "epoch: 44 ,loss: 0.08102365257516345\n",
      "epoch: 45 ,loss: 0.07767157485363071\n",
      "epoch: 46 ,loss: 0.07777290018811536\n",
      "epoch: 47 ,loss: 0.07450689387315118\n",
      "epoch: 48 ,loss: 0.07597414832284201\n",
      "epoch: 49 ,loss: 0.0722609714849163\n",
      "epoch: 50 ,loss: 0.07189336178431124\n",
      "epoch: 51 ,loss: 0.07226675354452657\n",
      "epoch: 52 ,loss: 0.07618344983836609\n",
      "epoch: 53 ,loss: 0.06939689898446424\n",
      "epoch: 54 ,loss: 0.06584930952106204\n",
      "epoch: 55 ,loss: 0.06851242879020379\n",
      "epoch: 56 ,loss: 0.06815466551836938\n",
      "epoch: 57 ,loss: 0.06548053909863617\n",
      "epoch: 58 ,loss: 0.06603552789878109\n",
      "epoch: 59 ,loss: 0.06350002174915027\n",
      "epoch: 60 ,loss: 0.0628939575628876\n",
      "epoch: 61 ,loss: 0.060876533393063016\n",
      "epoch: 62 ,loss: 0.060653856905824595\n",
      "epoch: 63 ,loss: 0.06051556250132096\n",
      "epoch: 64 ,loss: 0.058067243010091626\n",
      "epoch: 65 ,loss: 0.06097058325545239\n",
      "epoch: 66 ,loss: 0.05837996420003712\n",
      "epoch: 67 ,loss: 0.05762820434508357\n",
      "epoch: 68 ,loss: 0.05699844704444475\n",
      "epoch: 69 ,loss: 0.057383948917200826\n",
      "epoch: 70 ,loss: 0.05698818096648783\n",
      "epoch: 71 ,loss: 0.05701161289551873\n",
      "epoch: 72 ,loss: 0.05524036256290639\n",
      "epoch: 73 ,loss: 0.05573871985737131\n",
      "epoch: 74 ,loss: 0.05675524016067799\n",
      "epoch: 75 ,loss: 0.05380441239679546\n",
      "epoch: 76 ,loss: 0.05436276127772926\n",
      "epoch: 77 ,loss: 0.05513027912255988\n",
      "epoch: 78 ,loss: 0.05150548823431992\n",
      "epoch: 79 ,loss: 0.049184533153801585\n",
      "epoch: 80 ,loss: 0.05289662169661921\n",
      "epoch: 81 ,loss: 0.05090241708250633\n",
      "epoch: 82 ,loss: 0.0501013205630947\n",
      "epoch: 83 ,loss: 0.047352897622850915\n",
      "epoch: 84 ,loss: 0.050386754233938166\n",
      "epoch: 85 ,loss: 0.04879064558308198\n",
      "epoch: 86 ,loss: 0.04797017124932267\n",
      "epoch: 87 ,loss: 0.047436674895968395\n",
      "epoch: 88 ,loss: 0.047568696676127946\n",
      "epoch: 89 ,loss: 0.046003773993155216\n",
      "epoch: 90 ,loss: 0.04669520000754389\n",
      "epoch: 91 ,loss: 0.04600354120024105\n",
      "epoch: 92 ,loss: 0.04437378882122701\n",
      "epoch: 93 ,loss: 0.04494892343529252\n",
      "epoch: 94 ,loss: 0.04688071390824405\n",
      "epoch: 95 ,loss: 0.04463212541552749\n",
      "epoch: 96 ,loss: 0.04036123217192731\n",
      "epoch: 97 ,loss: 0.04399563998643206\n",
      "epoch: 98 ,loss: 0.04183647602296142\n",
      "epoch: 99 ,loss: 0.041845915161931056\n",
      "epoch: 100 ,loss: 0.04125240847651066\n",
      "epoch: 101 ,loss: 0.044562839797692\n",
      "epoch: 102 ,loss: 0.043596417502140695\n",
      "epoch: 103 ,loss: 0.0423398033034668\n",
      "epoch: 104 ,loss: 0.04145796327933129\n",
      "epoch: 105 ,loss: 0.041508881663129146\n",
      "epoch: 106 ,loss: 0.0403285998064699\n",
      "epoch: 107 ,loss: 0.04057700700486011\n",
      "epoch: 108 ,loss: 0.04080310421211442\n",
      "epoch: 109 ,loss: 0.03867732466005885\n",
      "epoch: 110 ,loss: 0.041003970637806315\n",
      "epoch: 111 ,loss: 0.03876829718245563\n",
      "epoch: 112 ,loss: 0.03917515035400958\n",
      "epoch: 113 ,loss: 0.03881687241922151\n",
      "epoch: 114 ,loss: 0.040676571494305945\n",
      "epoch: 115 ,loss: 0.03698940207856074\n",
      "epoch: 116 ,loss: 0.038703701865952664\n",
      "epoch: 117 ,loss: 0.03811591521485337\n",
      "epoch: 118 ,loss: 0.038633842456108854\n",
      "epoch: 119 ,loss: 0.03564392163086611\n",
      "epoch: 120 ,loss: 0.036051213701587245\n",
      "epoch: 121 ,loss: 0.037368627739692926\n",
      "epoch: 122 ,loss: 0.03629848122475609\n",
      "epoch: 123 ,loss: 0.03793840837289593\n",
      "epoch: 124 ,loss: 0.03547412752291001\n",
      "epoch: 125 ,loss: 0.03638336600175798\n",
      "epoch: 126 ,loss: 0.034269443840217365\n",
      "epoch: 127 ,loss: 0.03563140222290431\n",
      "epoch: 128 ,loss: 0.036117713040570966\n",
      "epoch: 129 ,loss: 0.03685573121306421\n",
      "epoch: 130 ,loss: 0.03423994648923625\n",
      "epoch: 131 ,loss: 0.034904868629917915\n",
      "epoch: 132 ,loss: 0.03287637434792576\n",
      "epoch: 133 ,loss: 0.03650701587904554\n",
      "epoch: 134 ,loss: 0.03572084586709928\n",
      "epoch: 135 ,loss: 0.03363538850178279\n",
      "epoch: 136 ,loss: 0.032890491715785286\n",
      "epoch: 137 ,loss: 0.03361121079386043\n",
      "epoch: 138 ,loss: 0.031884301956226706\n",
      "epoch: 139 ,loss: 0.03253919469800268\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "history=[]\n",
    "for epoch in range(140):  # number of epochs\n",
    "\n",
    "    running_loss = 0.0\n",
    "    count=0\n",
    "    for i, data in enumerate(trainer, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)#para gpu\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        count=count+1\n",
    "# print statistics\n",
    "    running_loss = running_loss/count\n",
    "    history.append(running_loss)\n",
    "    print('epoch:',epoch,',loss:',running_loss)\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output=net(mnist_train[0][0].unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.7668,  0.2746, -4.0083,  5.4703, -2.9090, 12.1799,  0.6811, -3.8624,\n",
       "         -1.9489, -1.6745]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(out):#out is the network output tensor, label is the output label\n",
    "    x,y=torch.max(out,1)\n",
    "    y=y.squeeze()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.48 %\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "correct=0\n",
    "for data in tester:\n",
    "    inputs,labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs=net(inputs)\n",
    "    predict=prediction(outputs)\n",
    "    total=total+labels.size(0)\n",
    "    correct=correct+(predict==labels).sum().item()\n",
    "accuracy=correct/total\n",
    "accuracy=accuracy*100\n",
    "print('accuracy:',accuracy,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.303502363945121,\n",
       " 2.3014023212481662,\n",
       " 2.299924540875563,\n",
       " 2.298519796399928,\n",
       " 2.2947225575762262,\n",
       " 2.2762315705386813,\n",
       " 1.7113339578164921,\n",
       " 0.7942710176968117,\n",
       " 0.5019483613942478,\n",
       " 0.39291277229150473,\n",
       " 0.3261896855414295,\n",
       " 0.28034946063497684,\n",
       " 0.2523413136728537,\n",
       " 0.23057553749571222,\n",
       " 0.2162103899585794,\n",
       " 0.19531095911190707,\n",
       " 0.18385944628257994,\n",
       " 0.17294467439148217,\n",
       " 0.16482574786585785,\n",
       " 0.15337889048971856,\n",
       " 0.14752267029430313,\n",
       " 0.1435559828644559,\n",
       " 0.13785926135046395,\n",
       " 0.13185965695948615,\n",
       " 0.12758359852344242,\n",
       " 0.12295589669903459,\n",
       " 0.12007057356602474,\n",
       " 0.1140067910652425,\n",
       " 0.11116698128915926,\n",
       " 0.10806241446831968,\n",
       " 0.10745644853758152,\n",
       " 0.10368147502734718,\n",
       " 0.10053271633475575,\n",
       " 0.09887406491299174,\n",
       " 0.09435063388857887,\n",
       " 0.09521257150957961,\n",
       " 0.093058493707194,\n",
       " 0.08896360733409299,\n",
       " 0.08596807849337297,\n",
       " 0.08808573910883113,\n",
       " 0.08421567974012417,\n",
       " 0.08517601951432507,\n",
       " 0.0820863131544928,\n",
       " 0.0794548255993105,\n",
       " 0.08102365257516345,\n",
       " 0.07767157485363071,\n",
       " 0.07777290018811536,\n",
       " 0.07450689387315118,\n",
       " 0.07597414832284201,\n",
       " 0.0722609714849163,\n",
       " 0.07189336178431124,\n",
       " 0.07226675354452657,\n",
       " 0.07618344983836609,\n",
       " 0.06939689898446424,\n",
       " 0.06584930952106204,\n",
       " 0.06851242879020379,\n",
       " 0.06815466551836938,\n",
       " 0.06548053909863617,\n",
       " 0.06603552789878109,\n",
       " 0.06350002174915027,\n",
       " 0.0628939575628876,\n",
       " 0.060876533393063016,\n",
       " 0.060653856905824595,\n",
       " 0.06051556250132096,\n",
       " 0.058067243010091626,\n",
       " 0.06097058325545239,\n",
       " 0.05837996420003712,\n",
       " 0.05762820434508357,\n",
       " 0.05699844704444475,\n",
       " 0.057383948917200826,\n",
       " 0.05698818096648783,\n",
       " 0.05701161289551873,\n",
       " 0.05524036256290639,\n",
       " 0.05573871985737131,\n",
       " 0.05675524016067799,\n",
       " 0.05380441239679546,\n",
       " 0.05436276127772926,\n",
       " 0.05513027912255988,\n",
       " 0.05150548823431992,\n",
       " 0.049184533153801585,\n",
       " 0.05289662169661921,\n",
       " 0.05090241708250633,\n",
       " 0.0501013205630947,\n",
       " 0.047352897622850915,\n",
       " 0.050386754233938166,\n",
       " 0.04879064558308198,\n",
       " 0.04797017124932267,\n",
       " 0.047436674895968395,\n",
       " 0.047568696676127946,\n",
       " 0.046003773993155216,\n",
       " 0.04669520000754389,\n",
       " 0.04600354120024105,\n",
       " 0.04437378882122701,\n",
       " 0.04494892343529252,\n",
       " 0.04688071390824405,\n",
       " 0.04463212541552749,\n",
       " 0.04036123217192731,\n",
       " 0.04399563998643206,\n",
       " 0.04183647602296142,\n",
       " 0.041845915161931056,\n",
       " 0.04125240847651066,\n",
       " 0.044562839797692,\n",
       " 0.043596417502140695,\n",
       " 0.0423398033034668,\n",
       " 0.04145796327933129,\n",
       " 0.041508881663129146,\n",
       " 0.0403285998064699,\n",
       " 0.04057700700486011,\n",
       " 0.04080310421211442,\n",
       " 0.03867732466005885,\n",
       " 0.041003970637806315,\n",
       " 0.03876829718245563,\n",
       " 0.03917515035400958,\n",
       " 0.03881687241922151,\n",
       " 0.040676571494305945,\n",
       " 0.03698940207856074,\n",
       " 0.038703701865952664,\n",
       " 0.03811591521485337,\n",
       " 0.038633842456108854,\n",
       " 0.03564392163086611,\n",
       " 0.036051213701587245,\n",
       " 0.037368627739692926,\n",
       " 0.03629848122475609,\n",
       " 0.03793840837289593,\n",
       " 0.03547412752291001,\n",
       " 0.03638336600175798,\n",
       " 0.034269443840217365,\n",
       " 0.03563140222290431,\n",
       " 0.036117713040570966,\n",
       " 0.03685573121306421,\n",
       " 0.03423994648923625,\n",
       " 0.034904868629917915,\n",
       " 0.03287637434792576,\n",
       " 0.03650701587904554,\n",
       " 0.03572084586709928,\n",
       " 0.03363538850178279,\n",
       " 0.032890491715785286,\n",
       " 0.03361121079386043,\n",
       " 0.031884301956226706,\n",
       " 0.03253919469800268]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(history):\n",
    "    epochs=range(len(history))\n",
    "    plt.plot(epochs,history,label='Training Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotData(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NeuraisTorch]",
   "language": "python",
   "name": "conda-env-NeuraisTorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
